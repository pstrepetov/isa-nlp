{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZGTNGBYQYwt"
   },
   "source": [
    "# Извлечение информации\n",
    "\n",
    "([Задание для семинара](#scrollTo=_r19P5FYuGk2&line=1&uniqifier=1), \n",
    "[Домашнее задание](#scrollTo=PbBbqFUeQPcS&line=1&uniqifier=1))\n",
    "\n",
    "\n",
    "Задачей извлечения информации является получение структурированного знания из набора неструктурированных текстов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhNznqSGSApl"
   },
   "source": [
    "## 1. Открытое извлечение информации (Open information extraction)\n",
    "\n",
    "Задача: извлечь из текста структурированную информацию в виде троек отношений: (объект, предикат, субъект)\n",
    "\n",
    "Как решается: поиском потомков предиката в синтаксическом дереве согласно некоторым правилам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EKuJ1tHgSdfm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "#from spacy.pipeline import SentenceSegmenter\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-Lk118jSApl",
    "outputId": "35e7fec0-f6ae-4d74-a691-e140b4074790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the brain to the heart and the skin \"Long Covid\" - the long-lasting impact of coronavirus infection - may be affecting people in four different ways, according to a review. And this could explain why some of those with continuing symptoms are not being believed or treated. There could be a huge psychological impact on people living with long-term Covid-19, the National Institute for Health Research report says. They need more support - and healthcare staff require better information. Life-chang\n"
     ]
    }
   ],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "url = 'https://www.bbc.com/news/health-54540544'\n",
    "\n",
    "html = request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "data = soup.findAll(text=True)\n",
    "visible_texts = filter(tag_visible, data)\n",
    "text = u\" \".join(t.strip() for t in visible_texts)\n",
    "print(text[700:1200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "br0lt7TtSApq"
   },
   "outputs": [],
   "source": [
    "SUBJECTS = [\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"]\n",
    "OBJECTS = [\"dobj\", \"dative\", \"attr\", \"oprd\"]\n",
    "\n",
    "def getSubsFromConjunctions(subs):\n",
    "    moreSubs = []\n",
    "    for sub in subs:\n",
    "        # rights is a generator\n",
    "        rights = list(sub.rights)\n",
    "        rightDeps = {tok.lower_ for tok in rights}\n",
    "        if \"and\" in rightDeps:\n",
    "            moreSubs.extend([tok for tok in rights if tok.dep_ in SUBJECTS or tok.pos_ == \"NOUN\"])\n",
    "            if len(moreSubs) > 0:\n",
    "                moreSubs.extend(getSubsFromConjunctions(moreSubs))\n",
    "    return moreSubs\n",
    "\n",
    "def getObjsFromConjunctions(objs):\n",
    "    moreObjs = []\n",
    "    for obj in objs:\n",
    "        # rights is a generator\n",
    "        rights = list(obj.rights)\n",
    "        rightDeps = {tok.lower_ for tok in rights}\n",
    "        if \"and\" in rightDeps:\n",
    "            moreObjs.extend([tok for tok in rights if tok.dep_ in OBJECTS or tok.pos_ == \"NOUN\"])\n",
    "            if len(moreObjs) > 0:\n",
    "                moreObjs.extend(getObjsFromConjunctions(moreObjs))\n",
    "    return moreObjs\n",
    "\n",
    "def getVerbsFromConjunctions(verbs):\n",
    "    moreVerbs = []\n",
    "    for verb in verbs:\n",
    "        rightDeps = {tok.lower_ for tok in verb.rights}\n",
    "        if \"and\" in rightDeps:\n",
    "            moreVerbs.extend([tok for tok in verb.rights if tok.pos_ == \"VERB\"])\n",
    "            if len(moreVerbs) > 0:\n",
    "                moreVerbs.extend(getVerbsFromConjunctions(moreVerbs))\n",
    "    return moreVerbs\n",
    "\n",
    "def findSubs(tok):\n",
    "    head = tok.head\n",
    "    while head.pos_ != \"VERB\" and head.pos_ != \"NOUN\" and head.head != head:\n",
    "        head = head.head\n",
    "    if head.pos_ == \"VERB\":\n",
    "        subs = [tok for tok in head.lefts if tok.dep_ == \"SUB\"]\n",
    "        if len(subs) > 0:\n",
    "            verbNegated = isNegated(head)\n",
    "            subs.extend(getSubsFromConjunctions(subs))\n",
    "            return subs, verbNegated\n",
    "        elif head.head != head:\n",
    "            return findSubs(head)\n",
    "    elif head.pos_ == \"NOUN\":\n",
    "        return [head], isNegated(tok)\n",
    "    return [], False\n",
    "\n",
    "def isNegated(tok):\n",
    "    negations = {\"no\", \"not\", \"n't\", \"never\", \"none\"}\n",
    "    for dep in list(tok.lefts) + list(tok.rights):\n",
    "        if dep.lower_ in negations:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def findSVs(tokens):\n",
    "    svs = []\n",
    "    verbs = [tok for tok in tokens if tok.pos_ == \"VERB\"]\n",
    "    for v in verbs:\n",
    "        subs, verbNegated = getAllSubs(v)\n",
    "        if len(subs) > 0:\n",
    "            for sub in subs:\n",
    "                svs.append((sub.orth_, \"!\" + v.orth_ if verbNegated else v.orth_))\n",
    "    return svs\n",
    "\n",
    "def getObjsFromPrepositions(deps):\n",
    "    objs = []\n",
    "    for dep in deps:\n",
    "        if dep.pos_ == \"ADP\" and dep.dep_ == \"prep\":\n",
    "            objs.extend([tok for tok in dep.rights if tok.dep_  in OBJECTS or (tok.pos_ == \"PRON\" and tok.lower_ == \"me\")])\n",
    "    return objs\n",
    "\n",
    "def getObjsFromAttrs(deps):\n",
    "    for dep in deps:\n",
    "        if dep.pos_ == \"NOUN\" and dep.dep_ == \"attr\":\n",
    "            verbs = [tok for tok in dep.rights if tok.pos_ == \"VERB\"]\n",
    "            if len(verbs) > 0:\n",
    "                for v in verbs:\n",
    "                    rights = list(v.rights)\n",
    "                    objs = [tok for tok in rights if tok.dep_ in OBJECTS]\n",
    "                    objs.extend(getObjsFromPrepositions(rights))\n",
    "                    if len(objs) > 0:\n",
    "                        return v, objs\n",
    "    return None, None\n",
    "\n",
    "def getObjFromXComp(deps):\n",
    "    for dep in deps:\n",
    "        if dep.pos_ == \"VERB\" and dep.dep_ == \"xcomp\":\n",
    "            v = dep\n",
    "            rights = list(v.rights)\n",
    "            objs = [tok for tok in rights if tok.dep_ in OBJECTS]\n",
    "            objs.extend(getObjsFromPrepositions(rights))\n",
    "            if len(objs) > 0:\n",
    "                return v, objs\n",
    "    return None, None\n",
    "\n",
    "def getAllSubs(v):\n",
    "    verbNegated = isNegated(v)\n",
    "    subs = [tok for tok in v.lefts if tok.dep_ in SUBJECTS and tok.pos_ != \"DET\"]\n",
    "    if len(subs) > 0:\n",
    "        subs.extend(getSubsFromConjunctions(subs))\n",
    "    else:\n",
    "        foundSubs, verbNegated = findSubs(v)\n",
    "        subs.extend(foundSubs)\n",
    "    return subs, verbNegated\n",
    "\n",
    "def getAllObjs(v):\n",
    "    # rights is a generator\n",
    "    rights = list(v.rights)\n",
    "    objs = [tok for tok in rights if tok.dep_ in OBJECTS]\n",
    "    objs.extend(getObjsFromPrepositions(rights))\n",
    "\n",
    "    potentialNewVerb, potentialNewObjs = getObjFromXComp(rights)\n",
    "    if potentialNewVerb is not None and potentialNewObjs is not None and len(potentialNewObjs) > 0:\n",
    "        objs.extend(potentialNewObjs)\n",
    "        v = potentialNewVerb\n",
    "    if len(objs) > 0:\n",
    "        objs.extend(getObjsFromConjunctions(objs))\n",
    "    return v, objs\n",
    "\n",
    "def findSVOs(tokens):\n",
    "    svos = []\n",
    "    verbs = [tok for tok in tokens if tok.pos_ == \"VERB\" and tok.dep_ != \"aux\"]\n",
    "    for v in verbs:\n",
    "        subs, verbNegated = getAllSubs(v)\n",
    "        # hopefully there are subs, if not, don't examine this verb any longer\n",
    "        if len(subs) > 0:\n",
    "            v, objs = getAllObjs(v)\n",
    "            for sub in subs:\n",
    "                for obj in objs:\n",
    "                    objNegated = isNegated(obj)\n",
    "                    svos.append((sub.lower_, \"!\" + v.lower_ if verbNegated or objNegated else v.lower_, obj.lower_))\n",
    "    return svos\n",
    "\n",
    "def printDeps(toks):\n",
    "    for tok in toks:\n",
    "        print(tok.orth_, tok.dep_, tok.pos_, tok.head.orth_, [t.orth_ for t in tok.lefts], [t.orth_ for t in tok.rights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fBtajtDdSApt",
    "outputId": "869b276c-915c-426f-f6c1-fdfd8eda2373"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('skip', 'help', 'account'),\n",
       " ('weather', 'sounds', 'war'),\n",
       " ('long', 'reads', 'coronavirus'),\n",
       " ('symptoms', 'affect', 'everything'),\n",
       " ('staff', 'require', 'information'),\n",
       " ('you', 'enable', 'javascript'),\n",
       " ('video', 'enable', 'javascript'),\n",
       " ('review', 'found', 'symptoms'),\n",
       " ('symptoms', 'affecting', 'everything'),\n",
       " ('some', 'had', 'stay'),\n",
       " ('who', 'had', 'infection'),\n",
       " ('coming', 'help', 'support'),\n",
       " ('others', 'reporting', 'experiences'),\n",
       " ('that', 'follow', 'infection'),\n",
       " ('clinics', 'set', 'covid'),\n",
       " ('she', 'assumed', 'those'),\n",
       " ('there', 'are', 'people'),\n",
       " ('record', 'having', 'covid'),\n",
       " ('who', 'suffering', 'more'),\n",
       " ('effects', 'put', 'burden'),\n",
       " ('sons', 'taken', 'source'),\n",
       " ('source', 'experiencing', 'symptoms'),\n",
       " ('symptoms', 'having', 'impact'),\n",
       " ('partner', 'experiencing', 'symptoms'),\n",
       " ('ash', 'experiencing', 'symptoms'),\n",
       " ('sons', 'take', 'cooking'),\n",
       " ('sons', 'take', 'cleaning'),\n",
       " ('we', 'need', 'support'),\n",
       " ('jo', 'had', 'pneumonia'),\n",
       " ('we', 'made', 'wills'),\n",
       " ('i', 'get', 'test'),\n",
       " ('we', 'answer', 'queries'),\n",
       " ('we', 'answer', 'treatment'),\n",
       " ('services', 'understand', 'review'),\n",
       " ('services', 'understand', 'experiences'),\n",
       " ('staff', 'understand', 'review'),\n",
       " ('staff', 'understand', 'experiences'),\n",
       " ('more', 'set', 'covid'),\n",
       " ('clinics', 'set', 'covid'),\n",
       " ('author', 'shares', 'nightmare'),\n",
       " ('video', 'shares', 'nightmare'),\n",
       " ('author', 'shares', 'nightmare'),\n",
       " ('storm', 'turns', 'city'),\n",
       " ('china', 'end', 'quarantine'),\n",
       " ('refugees', 'reach', 'indonesia'),\n",
       " ('people', 'risking', 'lives'),\n",
       " ('that', 'exist', 'ways'),\n",
       " ('town', 'giving', 'teens'),\n",
       " ('town', 'giving', 'beer'),\n",
       " ('town', 'giving', 'teens'),\n",
       " ('stars', 'knocking', 'bollywood'),\n",
       " ('countries', 'tackling', 'bills'),\n",
       " ('transplant', 'meet', 'army'),\n",
       " ('who', 'cut', 'children'),\n",
       " ('who', 'cut', 'treat'),\n",
       " ('storm', 'turns', 'buffalo'),\n",
       " ('books', 'stops', 'family'),\n",
       " ('iran', 'stops', 'family'),\n",
       " ('attack', 'leaves', '6'),\n",
       " ('nostalgia', 'revive', 'store'),\n",
       " ('that', 'exist', 'young'),\n",
       " ('china', 'stages', 'incursion'),\n",
       " ('taiwan', 'says', 'services'),\n",
       " ('terms', 'help', 'contact'),\n",
       " ('you', 'trust', 'advertise')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "tok = nlp(text)\n",
    "svos = findSVOs(tok)\n",
    "svos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_r19P5FYuGk2"
   },
   "source": [
    "### Применение\n",
    "\n",
    "Существуют готовые более сложные системы открытого извлечения информации. [Пример применения](https://openie.allenai.org/#).\n",
    "\n",
    "Модуль [CoreNLP OpenIE](https://nlp.stanford.edu/software/openie.html) для открытого извлечения информации, с помощью которого можно обнаруживать триплеты в неструктурированном тексте, основывается на нахождении синтаксических шаблонов в де­реве зависимостей следующим образом: исходное предложение разбивается на множество клауз, затем выделяются предикат и аргументы на основе правил, заданных вручную. В качестве преди­катов рассматриваются токены, находящиеся между двумя аргументами (именными группами) в дереве зависимостей, например, «play with» для клаузы «cats play with yarn». Также извлекаются номинальные отношения из именных групп, например, «’s» для именной группы «IBM’s researchgroup». Данная система демонстрирует качество 28.3% F-­меры на наборе данных [Knowledge Base Population](http://www.surdeanu.info/mihai/papers/kbp2013.pdf). \n",
    "\n",
    "**Задание (Семинар, 2 балла):** используйте модуль OpenIE для наивного поиска ответа на вопрос по тексту:\n",
    "\n",
    "> **Текст:** \"Born in Moscow, Pushkin was raised by nursemaids and French tutors, and spoke mostly French until the age of ten. He learned some Russian through his nanny, Arina Rodionovna, who he loved dearly. He published his first poem at the age of 15. When he finished school, as part of the first graduating class of the prestigious Imperial Lyceum in Tsarskoye Selo, near Saint Petersburg, his talent was already widely recognized on the Russian literary scene. At the Lyceum, he was a student of David Mara, a younger brother of French revolutionary Jean-Paul Marat. At After school, Pushkin plunged into the vibrant and raucous intellectual youth culture of St. Petersburg. St. Petersburg was then the capital of the Russian Empire. In 1820, Pushkin published his first long poem, Ruslan And Ludmila, with much controversy about its subject and style.\"\n",
    "\n",
    "> **Q:** \"Who taught Pushkin to speak Russian?\"\n",
    ">\n",
    "> **A:** ('He', 'learned Russian through', 'Arina Rodionovna')\n",
    "\n",
    "> **Q:** \"What was the capital of the Russian Empire?\"\n",
    ">\n",
    "> **A:** ('St. Petersburg', 'was capital of', 'Russian Empire')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwOp7klCw9R7"
   },
   "source": [
    "Загружаем Stanford CoreNLP:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLyhdihEww1s",
    "outputId": "93db9924-afd1-4a23-995a-9285f5c18325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-27 01:38:57--  https://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2018-10-05.zip [following]\n",
      "--2022-12-27 01:38:58--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2018-10-05.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 393239982 (375M) [application/zip]\n",
      "Saving to: ‘stanford-corenlp-full-2018-10-05.zip’\n",
      "\n",
      "stanford-corenlp-fu 100%[===================>] 375.02M  5.00MB/s    in 72s     \n",
      "\n",
      "2022-12-27 01:40:11 (5.18 MB/s) - ‘stanford-corenlp-full-2018-10-05.zip’ saved [393239982/393239982]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip && unzip -q stanford-corenlp-full-2018-10-05.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wIz_wvDLxNw8"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CORENLP_HOME\"] = 'stanford-corenlp-full-2018-10-05'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dKBKhEHxCXa"
   },
   "source": [
    "Устанавливаем библиотеку с оберткой CoreNLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrIJxXFjwYYx",
    "outputId": "629d742a-8f83-4898-9426-cc69e5d5f0be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting stanza\n",
      "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
      "\u001b[K     |████████████████████████████████| 691 kB 36.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from stanza) (1.13.0+cu116)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from stanza) (3.19.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stanza) (1.21.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from stanza) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from stanza) (4.64.1)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
      "\u001b[K     |████████████████████████████████| 240 kB 68.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from stanza) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->stanza) (4.4.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (2022.12.7)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=1a1ed803077c7d7ede0196cc9e44defefdc509441e9972b874573ab72767aade\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, stanza\n",
      "Successfully installed emoji-2.2.0 stanza-1.4.2\n"
     ]
    }
   ],
   "source": [
    "! pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYg81FdNxhe4",
    "outputId": "95ca0033-2506-42ab-ae12-ddcb1abbc920"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:stanza:Directory stanford-corenlp-full-2018-10-05 already exists. Please install CoreNLP to a new directory.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "stanza.install_corenlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ILEkx3Bw78s"
   },
   "source": [
    "Запускаем CoreNLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_EuK6taxYTl",
    "outputId": "43ffb574-ac51-461a-b0d5-b9223a2da7e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:stanza:Writing properties to tmp file: corenlp_server-a750e583b82b4c3a.props\n",
      "INFO:stanza:Starting server with command: java -Xmx5G -cp stanford-corenlp-full-2018-10-05/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 150000000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-a750e583b82b4c3a.props -annotators openie -preload -outputFormat serialized\n"
     ]
    }
   ],
   "source": [
    "from stanza.server import CoreNLPClient\n",
    "\n",
    "client = CoreNLPClient(timeout=150000000, be_quiet=True, annotators=['openie'], \n",
    "endpoint='http://localhost:9001')\n",
    "client.start()\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xseMMmc-xqvJ"
   },
   "source": [
    "Аннотируем текст, смотрим на триплеты, извлеченные из первого предложения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UBp19Ebg6LAl"
   },
   "outputs": [],
   "source": [
    "paragraph = \"Born in Moscow, Pushkin was raised by nursemaids and French tutors, and spoke mostly French until the age of ten. He learned some Russian through his nanny, Arina Rodionovna, who he loved dearly. He published his first poem at the age of 15. When he finished school, as part of the first graduating class of the prestigious Imperial Lyceum in Tsarskoye Selo, near Saint Petersburg, his talent was already widely recognized on the Russian literary scene. At the Lyceum, he was a student of David Mara, a younger brother of French revolutionary Jean-Paul Marat. At After school, Pushkin plunged into the vibrant and raucous intellectual youth culture of St. Petersburg. St. Petersburg was then the capital of the Russian Empire. In 1820, Pushkin published his first long poem, Ruslan And Ludmila, with much controversy about its subject and style.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XNOK6VW6xzDy"
   },
   "outputs": [],
   "source": [
    "ann = client.annotate(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySYQoUVux1nr",
    "outputId": "c33c957e-a765-4957-8fb9-e21f10a6eee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject: \"Pushkin\"\n",
      "relation: \"was raised by\"\n",
      "object: \"nursemaids\"\n",
      "confidence: 1.0\n",
      "tree {\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 5\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 6\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 7\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 8\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 9\n",
      "  }\n",
      "  edge {\n",
      "    source: 7\n",
      "    target: 5\n",
      "    dep: \"nsubjpass\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 7\n",
      "    target: 6\n",
      "    dep: \"auxpass\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 7\n",
      "    target: 9\n",
      "    dep: \"nmod:agent\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 9\n",
      "    target: 8\n",
      "    dep: \"case\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  root: 7\n",
      "}\n",
      "subjectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 4\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 5\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 6\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 7\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 8\n",
      "}\n",
      "\n",
      "\n",
      "subject: \"Pushkin\"\n",
      "relation: \"Born in\"\n",
      "object: \"Moscow\"\n",
      "confidence: 1.0\n",
      "tree {\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 1\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 2\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 3\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 5\n",
      "  }\n",
      "  edge {\n",
      "    source: 1\n",
      "    target: 3\n",
      "    dep: \"nmod:in\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 1\n",
      "    target: 5\n",
      "    dep: \"nsubj\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 3\n",
      "    target: 2\n",
      "    dep: \"case\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  root: 1\n",
      "}\n",
      "subjectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 4\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 0\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 1\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 2\n",
      "}\n",
      "\n",
      "\n",
      "subject: \"Pushkin\"\n",
      "relation: \"spoke until\"\n",
      "object: \"age of ten\"\n",
      "confidence: 1.0\n",
      "tree {\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 18\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 20\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 5\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 21\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 22\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 15\n",
      "  }\n",
      "  edge {\n",
      "    source: 20\n",
      "    target: 18\n",
      "    dep: \"case\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 20\n",
      "    target: 22\n",
      "    dep: \"nmod:of\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 22\n",
      "    target: 21\n",
      "    dep: \"case\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 15\n",
      "    target: 20\n",
      "    dep: \"nmod:until\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 15\n",
      "    target: 5\n",
      "    dep: \"nsubj\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  root: 15\n",
      "}\n",
      "subjectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 4\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 14\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 17\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 19\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 20\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 21\n",
      "}\n",
      "\n",
      "\n",
      "subject: \"Pushkin\"\n",
      "relation: \"spoke\"\n",
      "object: \"French\"\n",
      "confidence: 1.0\n",
      "tree {\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 17\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 5\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 15\n",
      "  }\n",
      "  edge {\n",
      "    source: 15\n",
      "    target: 17\n",
      "    dep: \"xcomp\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 15\n",
      "    target: 5\n",
      "    dep: \"nsubj\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  root: 15\n",
      "}\n",
      "subjectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 4\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 14\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 16\n",
      "}\n",
      "\n",
      "\n",
      "subject: \"Pushkin\"\n",
      "relation: \"spoke\"\n",
      "object: \"mostly French\"\n",
      "confidence: 1.0\n",
      "tree {\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 16\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 17\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 5\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 15\n",
      "  }\n",
      "  edge {\n",
      "    source: 17\n",
      "    target: 16\n",
      "    dep: \"advmod\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 15\n",
      "    target: 17\n",
      "    dep: \"xcomp\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 15\n",
      "    target: 5\n",
      "    dep: \"nsubj\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  root: 15\n",
      "}\n",
      "subjectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 4\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 14\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 15\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 16\n",
      "}\n",
      "\n",
      "\n",
      "subject: \"Pushkin\"\n",
      "relation: \"spoke until\"\n",
      "object: \"age\"\n",
      "confidence: 1.0\n",
      "tree {\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 18\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 20\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 5\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 15\n",
      "  }\n",
      "  edge {\n",
      "    source: 20\n",
      "    target: 18\n",
      "    dep: \"case\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 15\n",
      "    target: 20\n",
      "    dep: \"nmod:until\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 15\n",
      "    target: 5\n",
      "    dep: \"nsubj\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  root: 15\n",
      "}\n",
      "subjectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 4\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 14\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 17\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 19\n",
      "}\n",
      "\n",
      "\n",
      "subject: \"Pushkin\"\n",
      "relation: \"was\"\n",
      "object: \"raised\"\n",
      "confidence: 1.0\n",
      "tree {\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 5\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 6\n",
      "  }\n",
      "  node {\n",
      "    sentenceIndex: 0\n",
      "    index: 7\n",
      "  }\n",
      "  edge {\n",
      "    source: 7\n",
      "    target: 5\n",
      "    dep: \"nsubjpass\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  edge {\n",
      "    source: 7\n",
      "    target: 6\n",
      "    dep: \"auxpass\"\n",
      "    isExtra: false\n",
      "    sourceCopy: 0\n",
      "    targetCopy: 0\n",
      "    language: UniversalEnglish\n",
      "  }\n",
      "  root: 7\n",
      "}\n",
      "subjectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 4\n",
      "}\n",
      "relationTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 5\n",
      "}\n",
      "objectTokens {\n",
      "  sentenceIndex: 0\n",
      "  tokenIndex: 6\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for triple in ann.sentence[0].openieTriple:\n",
    "  print(triple)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SyJ9CUUnGlrG"
   },
   "outputs": [],
   "source": [
    "triples = []\n",
    "# ToDO: Здесь заполняем список триплетов значениями (субъект, предикат, объект), чтобы сохранялся вывод следующей ячейки\n",
    "for sent in ann.sentence:\n",
    "  d = sent.openieTriple\n",
    "  for triple in sent.openieTriple:\n",
    "    triples.append((triple.subject, triple.relation, triple.object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0-1ngKAx7-K",
    "outputId": "0c9c8291-262d-4d9a-aa0b-ab7af32fc267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55,\n",
       " [('Pushkin', 'was raised by', 'nursemaids'),\n",
       "  ('Pushkin', 'Born in', 'Moscow'),\n",
       "  ('Pushkin', 'spoke until', 'age of ten')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(triples), triples[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0U00mvxJwKQ"
   },
   "source": [
    "Находим ответ - триплет, в котором предикат больше всего похож на вопрос:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fCElztQRCUOt"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), norm='l2')\n",
    "t_vectors = vectorizer.fit_transform([tr[1] for tr in triples])\n",
    "\n",
    "def find_answer(question):\n",
    "  \"\"\" Всем уже знакомое вычисление косинусной близости \"\"\"\n",
    "  q_vec = vectorizer.transform([question])\n",
    "  cos_sim = q_vec @ t_vectors.T\n",
    "  \n",
    "  return triples[np.argmax(cos_sim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvajkgaOBQ_1",
    "outputId": "f2eb277b-1bea-4e4f-81b3-7421dd2e50e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('He', 'learned Russian through', 'Arina Rodionovna')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_answer(\"Who taught Pushkin to speak Russian?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMUpv6NDGBcT",
    "outputId": "c12a8d7c-3ac2-4cbd-c171-ddeebf8b7077"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('St. Petersburg', 'was capital of', 'Russian Empire')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_answer(\"What was the capital of the Russian Empire?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdcxMqhlHLxd",
    "outputId": "f77bbc5c-f1bc-4497-966a-4fa59e1fb612"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Pushkin', 'Born in', 'Moscow')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ToDO: Придумайте свой пример, для которого сработает этот метод\n",
    "find_answer(\"Where Pushkin was born?\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jhNznqSGSApl"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
